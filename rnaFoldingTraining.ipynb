{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "053f5b86",
   "metadata": {},
   "source": [
    "packages used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e9c8460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install torch\n",
    "# !pip install matplotlib\n",
    "# !pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6077209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from sys import platform\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddd966cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "hiddenDim = 512\n",
    "batch_size = 16\n",
    "outputDim = 3 # three coords for each output\n",
    "learning_rate = 0.0001\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2132ce",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b6c2cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input processing\n",
    "\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    inputDir = \"/kaggle/input/\"\n",
    "elif platform == \"darwin\":\n",
    "    inputDir = \".\"\n",
    "trainSeqs = pd.read_csv(os.path.join(inputDir,\"stanford-rna-3d-folding/train_sequences.csv\"))\n",
    "\n",
    "\n",
    "\n",
    "nucs = functools.reduce(set.union,trainSeqs[\"sequence\"].apply(list).map(set).to_list()) # get all unique nucs at all positions\n",
    "nucs.add(\"NONE\")\n",
    "nucToIdx = {nuc: i for i, nuc in enumerate(nucs)}\n",
    "\n",
    "def processSeqDF(inputSeqs,nucToIdx):\n",
    "    indexSeqs = inputSeqs[\"sequence\"].apply(list)\n",
    "    indexSeqs = indexSeqs.apply(pd.Series).fillna(\"NONE\")\n",
    "    idxToKeep = torch.tensor((indexSeqs != 'NONE').to_numpy(int),dtype=int).unsqueeze(-1)\n",
    "\n",
    "\n",
    "\n",
    "    indexSeqs = indexSeqs.map(lambda nuc: nucToIdx[nuc])\n",
    "    indexSeqs.index = inputSeqs[\"target_id\"]\n",
    "\n",
    "    seqTensor = torch.tensor(indexSeqs.values, dtype=torch.int)\n",
    "    return seqTensor, indexSeqs, idxToKeep\n",
    "\n",
    "seqTensor,_ , idxToKeep = processSeqDF(trainSeqs, nucToIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b559522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/jd/kcpyjtsx6b7bft_5y_ps8kzm0000gn/T/ipykernel_22319/2662310586.py:4: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  trainLabels[\"ID\"] = trainLabels[\"ID\"].map(lambda x: re.sub(\"_\\d+$\",\"\",x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -8.8940,  -6.2430,  -4.4540,  -3.7060,  -5.6050, -10.1530, -13.1060,\n",
      "        -18.6920, -18.3870, -19.1380, -17.9000, -13.7290,  -8.1270,  -3.6100,\n",
      "          0.0590,   0.5840,   1.4240,   0.0000,   0.0000,   0.0000],\n",
      "       dtype=torch.float64)\n",
      "tensor([-8.8940,  2.6510,  1.7890,  0.7480, -1.8990, -4.5480, -2.9530, -5.5860,\n",
      "         0.3050, -0.7510,  1.2380,  4.1710,  5.6020,  4.5170,  3.6690,  0.5250,\n",
      "         0.8400, -1.4240,  0.0000,  0.0000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# output label processing\n",
    "\n",
    "trainLabels = pd.read_csv(os.path.join(inputDir,\"stanford-rna-3d-folding/train_labels.csv\"))\n",
    "trainLabels[\"ID\"] = trainLabels[\"ID\"].map(lambda x: re.sub(\"_\\d+$\",\"\",x))\n",
    "pivotedLabels = trainLabels.pivot(index=\"ID\",columns=\"resid\",values=[\"x_1\",\"y_1\",\"z_1\"])\n",
    "pivotedLabels.fillna(0,inplace=True)\n",
    "pivotedLabels.shape\n",
    "labelTensor = torch.tensor(pivotedLabels.to_numpy().reshape(pivotedLabels.shape[0],3,-1)).transpose(1,2)\n",
    "print(labelTensor[10,:20,0])\n",
    "\n",
    "labelTensor = labelTensor - torch.concat((torch.zeros_like(labelTensor[:,:1]), labelTensor[:,:-1]), dim=1)\n",
    "\n",
    "# 10, 5, 10 = 10, 5, 10\n",
    "# 20, 13,5 = 10, 8, -5 labelTensor[:,1:]\n",
    "\n",
    "# 10 - 0 20 - 10\n",
    "# 10, 20,25, 28,\n",
    "\n",
    "\n",
    "print(labelTensor[10,:20,0])\n",
    "# labelTensor = torch.nn.functional.normalize(labelTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0042e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data loader\n",
    "train_loader = DataLoader(list(zip(seqTensor, idxToKeep,labelTensor)),batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a392eaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test input processing \n",
    "testSeqs = pd.read_csv(os.path.join(inputDir,\"stanford-rna-3d-folding/test_sequences.csv\"))\n",
    "seqTensor, indexSeqs, idxToKeep = processSeqDF(testSeqs, nucToIdx)\n",
    "test_loader = DataLoader(list(zip(seqTensor,idxToKeep, indexSeqs.index)), batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29547556",
   "metadata": {},
   "source": [
    "# model architecture and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91478197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49b74ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotRollingAvg(losses,window = 100):\n",
    "    plt.plot(losses,alpha=0.5)\n",
    "    \n",
    "    plt.plot([sum(losses[i:i+window]) / len(losses[i:i+window])  for i in range(len(losses))],color=\"b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d0e9318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, opter, train_loader,numEpochs = 100,logFreq = 5):\n",
    "    losses = []\n",
    "    try:\n",
    "        with open(\"trainingLog.txt\", \"a\") as logFile:\n",
    "            for epoch in range(numEpochs):\n",
    "                for step, (batchSeqs, batchIdx, batchLabels) in enumerate(train_loader):\n",
    "                    batchSeqs = batchSeqs.to(device)\n",
    "                    batchLabels = batchLabels.to(device)\n",
    "                    batchIdx = batchIdx.to(device)\n",
    "                    opter.zero_grad()\n",
    "\n",
    "                    \n",
    "                    seqLens = torch.sum(batchIdx,axis=1)\n",
    "\n",
    "                    maxLen = max(seqLens)\n",
    "                    batchSeqs = batchSeqs[:,:maxLen]\n",
    "                    batchIdx = batchIdx[:,:maxLen]\n",
    "                    batchLabels = batchLabels[:,:maxLen]\n",
    "                    # MSE that accounts for differing lengths. This makes short sequences have a similar error to long sequences and zeros out errors on non existant positions\n",
    "                    loss = torch.sum((batchLabels - model(batchSeqs)) ** 2 * batchIdx / seqLens.unsqueeze(-1)) \n",
    "                    \n",
    "                    losses.append(loss.item())\n",
    "                    loss.backward()\n",
    "                    opter.step()\n",
    "\n",
    "                    if step % logFreq == 0:\n",
    "                        print(\"epoch\", epoch,\"step\", step, torch.mean(torch.tensor(losses[-logFreq:])), file=logFile,flush=True)\n",
    "                        print(\"epoch\", epoch,\"step\", step, torch.mean(torch.tensor(losses[-logFreq:])),flush=True)\n",
    "                        torch.save(model, \"model.pt\")\n",
    "    except KeyboardInterrupt:\n",
    "        return losses\n",
    "    # except:\n",
    "    #     torch.save(model, \"model.pt\")\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "659e2440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made model with 6309891 parameters of which 6309891 are trainable\n"
     ]
    }
   ],
   "source": [
    "numDistinctInputs = len(nucs)\n",
    "model = Model(numDistinctInputs, hiddenDim, outputDim, device)\n",
    "\n",
    "opter = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "# losses = train(model, opter, train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f50ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotRollingAvg(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
