{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "053f5b86",
   "metadata": {},
   "source": [
    "packages used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e9c8460",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install torch\n",
    "# !pip install matplotlib\n",
    "# !pip install \"numpy<2\n",
    "# !pip install torch_geometric\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6077209b",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cazcullimore/dev/rnaFolding/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/cazcullimore/dev/rnaFolding/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from accelerate import Accelerator, DeepSpeedPlugin\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "import re\n",
    "from time import time\n",
    "import numpy as np\n",
    "import os\n",
    "from sys import platform\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    !rm rnaModel.py\n",
    "    !wget https://raw.githubusercontent.com/SomeoneNamedCaz/RNAFolding/refs/heads/main/rnaModel.py\n",
    "import importlib\n",
    "import rnaModel\n",
    "importlib.reload(rnaModel)\n",
    "from glob import glob\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddd966cc",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<accelerate.accelerator.Accelerator object at 0x1051af280>\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "hiddenDim = 64\n",
    "batch_size = 16\n",
    "outputDim = 1 # one dist for each output TODO: try onehot outputs\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# deepspeed_plugin = DeepSpeedPlugin(zero_stage=2, gradient_accumulation_steps=2)\n",
    "# accelerator = Accelerator(mixed_precision='fp16', deepspeed_plugin=deepspeed_plugin)\n",
    "accelerator = Accelerator()\n",
    "\n",
    "# device = accelerator.device#\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(accelerator)\n",
    "DISTOGRAM_FILE_NAME = \"distogram.pt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2132ce",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b6c2cb4",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# input processing\n",
    "\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    DISTOGRAM_DIR = \"/kaggle/input/distograms/distograms\"\n",
    "    inputDir = \"/kaggle/input/\"\n",
    "elif platform == \"darwin\":\n",
    "    inputDir = \".\"\n",
    "    DISTOGRAM_DIR = \"distograms\"\n",
    "trainSeqs = pd.read_csv(os.path.join(inputDir,\"stanford-rna-3d-folding/train_sequences.csv\"))\n",
    "\n",
    "\n",
    "\n",
    "nucs = functools.reduce(set.union,trainSeqs[\"sequence\"].apply(list).map(set).to_list()) # get all unique nucs at all positions\n",
    "nucs.add(\"NONE\")\n",
    "nucToIdx = {nuc: i for i, nuc in enumerate(nucs)}\n",
    "\n",
    "def processSeqDF(inputSeqs,nucToIdx):\n",
    "    indexSeqs = inputSeqs[\"sequence\"].apply(list)\n",
    "    indexSeqs = indexSeqs.apply(pd.Series).fillna(\"NONE\")\n",
    "    idxToKeep = torch.tensor((indexSeqs != 'NONE').to_numpy(int),dtype=int).unsqueeze(-1)\n",
    "\n",
    "\n",
    "\n",
    "    indexSeqs = indexSeqs.map(lambda nuc: nucToIdx[nuc])\n",
    "    indexSeqs.index = inputSeqs[\"target_id\"]\n",
    "\n",
    "    seqTensor = torch.tensor(indexSeqs.values, dtype=torch.int)\n",
    "    return seqTensor, indexSeqs, idxToKeep\n",
    "\n",
    "trainSeqTensor,_ , trainIdxToKeep = processSeqDF(trainSeqs, nucToIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b559522",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# output label processing\n",
    "\n",
    "trainLabels = pd.read_csv(os.path.join(inputDir,\"stanford-rna-3d-folding/train_labels.csv\"))\n",
    "trainLabels[\"ID\"] = trainLabels[\"ID\"].map(lambda x: re.sub(r\"_\\d+$\",\"\",x))\n",
    "pivotedLabels = trainLabels.pivot(index=\"ID\",columns=\"resid\",values=[\"x_1\",\"y_1\",\"z_1\"])\n",
    "pivotedLabels.fillna(0,inplace=True)\n",
    "pivotedLabels.shape\n",
    "labelTensor = torch.tensor(pivotedLabels.to_numpy().reshape(pivotedLabels.shape[0],3,-1)).transpose(1,2)\n",
    "\n",
    "\n",
    "# labelTensor = labelTensor - torch.concat((torch.zeros_like(labelTensor[:,:1]), labelTensor[:,:-1]), dim=1)\n",
    "\n",
    "def converToDistogramSlow(allData):\n",
    "    \"\"\" coords tensor [residue number, coord index(0->x,1->y,2->z)]\n",
    "            returns: tensor [residue number,residue number] # distances between two points\n",
    "    \"\"\" \n",
    "    \n",
    "    for entryIndex, coords in enumerate(allData):\n",
    "        for resIdx, residue in enumerate(coords):\n",
    "            # print(help(torch.linalg.vector_norm))\n",
    "            distancesToResidue = torch.linalg.vector_norm(coords - residue, dim=-1).unsqueeze(0)\n",
    "            if resIdx == 0:\n",
    "                entryDistances = distancesToResidue\n",
    "            else:\n",
    "                entryDistances = torch.concat((entryDistances,distancesToResidue))\n",
    "        entryDistances = entryDistances.unsqueeze(0)\n",
    "        if entryIndex == 0:\n",
    "            allDistances = entryDistances\n",
    "        else:\n",
    "            allDistances = torch.concat((allDistances,entryDistances))\n",
    "        \n",
    "    return allDistances\n",
    "\n",
    "def convertToDistogramFast(coords):\n",
    "    \"\"\" coords tensor [residue number, coord index(0->x,1->y,2->z)]\n",
    "            returns: tensor [residue number,residue number] # distances between two points\n",
    "    \"\"\"   \n",
    "\n",
    "    diff = coords[:,:,None] - coords[:,None,:]\n",
    "    dists = torch.linalg.vector_norm(diff,dim=-1)\n",
    "    dists = dists.half()\n",
    "    return dists\n",
    "\n",
    "assert (convertToDistogramFast(labelTensor[:10,:20]) == converToDistogramSlow(labelTensor[:10,:20]).half()).all()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5ca1752",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def makeDistogramDir(path, seqTensor, idxToKeep, remakeAll=False):\n",
    "    os.makedirs(path, exist_ok=True,)\n",
    "    t0 = time()\n",
    "    for i, _ in enumerate(labelTensor):\n",
    "        \n",
    "        savePath = os.path.join(path,re.sub(r\"\\.(\\w+)$\", str(i) + r\".\\1\",DISTOGRAM_FILE_NAME))\n",
    "        if not os.path.exists(savePath) or remakeAll:\n",
    "            out = convertToDistogramFast(labelTensor[i].unsqueeze(-1))\n",
    "            torch.save((seqTensor[i], idxToKeep[i], out), savePath)\n",
    "    print(\"took\",time()-t0,\"to make distograms\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2465e842",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# makeDistogramDir(DISTOGRAM_DIR,trainSeqTensor, trainIdxToKeep, remakeAll=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9840250",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RNADataset(Dataset):\n",
    "    def __init__(self, seqTensor, idxToKeep, distogramDir):\n",
    "        super().__init__()\n",
    "        self.distogramPaths = glob(os.path.join(distogramDir,\"*\"))\n",
    "        self.seqTensor = seqTensor\n",
    "        self.idxToKeep = idxToKeep\n",
    "    def __len__(self):\n",
    "        return len(self.distogramPaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.load(self.distogramPaths[idx]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39df809a",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.510048 MB\n",
      "29.020096 MB\n"
     ]
    }
   ],
   "source": [
    "print(trainSeqTensor.numel() * trainSeqTensor.element_size() / 1e6, \"MB\")\n",
    "print(trainIdxToKeep.numel() * trainIdxToKeep.element_size() / 1e6, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0042e6ca",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# make data loader\n",
    "train_dataset = RNADataset(trainSeqTensor, trainIdxToKeep, DISTOGRAM_DIR)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a392eaac",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## test input processing \n",
    "testSeqs = pd.read_csv(os.path.join(inputDir,\"stanford-rna-3d-folding/test_sequences.csv\"))\n",
    "testSeqTensor, indexSeqs, testIndexToKeep = processSeqDF(testSeqs, nucToIdx)\n",
    "test_loader = DataLoader(list(zip(testSeqTensor,trainIdxToKeep, testIndexToKeep)), batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29547556",
   "metadata": {},
   "source": [
    "# model architecture and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49b74ab2",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plotRollingAvg(losses,window = 100):\n",
    "    plt.plot(losses,alpha=0.5)\n",
    "    \n",
    "    plt.plot([sum(losses[i:i+window]) / len(losses[i:i+window])  for i in range(len(losses))],color=\"b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0e9318",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def train(model, opter, train_loader,numEpochs = 100,logFreq = 5):\n",
    "    losses = []\n",
    "    try:\n",
    "        with open(\"trainingLog.txt\", \"a\") as logFile:\n",
    "            for epoch in range(numEpochs):\n",
    "                for step, (batchSeqs, batchIdx, batchLabels) in enumerate(train_loader):\n",
    "                    # batchSeqs = batchSeqs.to(device)\n",
    "                    # batchLabels = batchLabels.to(device)\n",
    "                    # batchIdx = batchIdx.to(device)\n",
    "                    opter.zero_grad()\n",
    "                    \n",
    "                    \n",
    "                    seqLens = torch.sum(batchIdx,axis=1).squeeze()\n",
    "\n",
    "                    maxLen = min(max(seqLens),300)\n",
    "                    batchSeqs = batchSeqs[:,:maxLen]\n",
    "                    batchIdx = batchIdx[:,:maxLen].unsqueeze(2)\n",
    "                    print(\"index\",batchIdx.shape)\n",
    "                    batchLabels = batchLabels.transpose(1,-1) # TODO: remake dataset with this included and remove this line\n",
    "                    batchLabels = batchLabels[:,:maxLen,:maxLen]\n",
    "                    print(\"batch labels\", batchLabels.shape)\n",
    "                    # MSE that accounts for differing lengths. This makes short sequences have a similar error to long sequences and zeros out errors on non existant positions\n",
    "                    mse = (batchLabels - model(batchSeqs)) ** 2\n",
    "\n",
    "                    print(\"Outside: input size\", batchSeqs.size(),\"output_size\", mse.size())\n",
    "                    loss = torch.mean(torch.sum(mse * batchIdx,dim=(1,2,3)) / seqLens)\n",
    "                    \n",
    "                    losses.append(loss.item())\n",
    "                    # loss.backward()\n",
    "                    accelerator.backward(loss)\n",
    "                    opter.step()\n",
    "\n",
    "                    if step % logFreq == 0:\n",
    "                        print(\"epoch\", epoch,\"step\", step, torch.mean(torch.tensor(losses[-logFreq:])), file=logFile,flush=True)\n",
    "                        print(\"epoch\", epoch,\"step\", step, torch.mean(torch.tensor(losses[-logFreq:])),flush=True)\n",
    "                        torch.save(model, \"model.pt\")\n",
    "    except KeyboardInterrupt:\n",
    "        return losses\n",
    "    # except:\n",
    "    #     torch.save(model, \"model.pt\")\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659e2440",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made model with 692609 parameters of which 692609 are trainable\n"
     ]
    }
   ],
   "source": [
    "numDistinctInputs = len(nucs)\n",
    "model = rnaModel.RNAModel(numDistinctInputs, hiddenDim, hiddenDim, outputDim)\n",
    "\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#   print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#   model = nn.DataParallel(model)\n",
    "\n",
    "# model.to(device)\n",
    "\n",
    "opter = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "model, opter, train_loader = accelerator.prepare(model, opter, train_loader)\n",
    "losses = train(model, opter, train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f50ae31",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# plotRollingAvg(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b08015c",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(\"/Users/cazcullimore/Downloads/trainingLog.txt\") as file:\n",
    "    data = \"\".join(file.readlines())\n",
    "    floatLosses = [float(elt) for elt in re.findall(r\"\\((\\d+\\.\\d*)\\)\",data)]\n",
    "    plotRollingAvg(floatLosses)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12276181,
     "sourceId": 87793,
     "sourceType": "competition"
    },
    {
     "datasetId": 7320630,
     "sourceId": 11664655,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
